---
title: "PAP Template for Experiment Projects - Project 3"
author: "Project 3"
date: "April 2021"
output: 
  html_document:
    highlight: haddock
    theme: journal
    number_sections: no
    toc: yes
    toc_depth: 5
    toc_float: yes
---

<style>
div.blue { background-color:#e6f0ff; border-radius: 5px; padding: 20px;}
</style>

<style>
div.medblue { background-color: #b3d1ff; border-radius: 5px; padding: 5px;}
</style>

<style>
div.darkblue { background-color: #9ac2ff; border-radius: 5px; padding: 5px;}
</style>

## Instructions: 
This is a template of an experimental plan document, or what is called a Pre-analysis Plan (PAP). In this course, your team will work together on producing a PAP to plan your experiment. It will be one of your final deliverables.[^1]

The PAP is a planning tool to help your team 1) structure the research from design to analysis, 2) think through all the necessary steps before implementation, 3) lay out specific hypotheses you want to test, and 4) plan for analysis before the data comes in. This plan lowers the risk of ex-post cherry-picking of causal relations through precisely defining the hypotheses, outcomes, and tests prior to data collection and/or analysis.

This template is produced to help you frame the planning of your experiment. We have filled in the template based on the Pre-analysis Plan for "Optimal Policies to Battle the Coronavirus Infodemic Among Social Media Users in Sub-Saharan Africa" (Offer-Westort, Rosenzweig, and Athey, 2020). Note that we have adapted and simplified some sections.

You should be able to complete a PAP for your experiment using resources such as the Project Packet, discussions with partners and experts, and the experimental design tutorials.

[^1]: This tutorial was originally developed for the Spring 2021 course, ALP301 Data-Driven Impact.


```{r setup, include = FALSE}
set.seed(95126)
knitr::opts_chunk$set(
  eval = TRUE,
  echo = TRUE,
  warning = FALSE,
  message = FALSE
)
```


---

## Motivation

Colorado’s unique election system is often referred to as the “gold standard for the nation" and has some of the highest voter turnout rates in the country. Since 2013, all registered voters in the state receive their ballot in the mail and have a variety of ways to return it (via mail, drop box, or in person). In 2017, Colorado became the first state to use a security feature, Risk-Limiting Audit (RLA), to check and verify electoral results.

While many academics, NGOs, and election officials view RLAs as an ideal way to confirm the integrity of the election and final vote count, the RLA process is often challenging to convey to the general public. Communicating the importance and security of RLAs is critical, particularly as other states are looking to implement RLAs in future elections.

...

The partners for this project include the Colorado State government office and a cross-disciplinary group at Stanford, including researchers and policy experts at the Stanford Internet Observatory, that studies abuse of information technologies and develops a curriculum on trust and safety.

The goal of this project is to learn about the effective means to communicate the RLA technology to the public, and improve public trust in the election process. To achieve this goal, the project team will design an experiment with experts on RLAs. This project would directly inform election policy across the country, enabling election officials to rebuild voter confidence in the integrity of elections. The group will test the effectivness of several interventions to increase confidence in using RLAs to verify election results, including different messages to convey why RLAs ensure integrity in the election from different credible messengers (e.g. teacher, judges). Our outcome of interest will be trust in the individual's State election results from learning about RLAs. Individuals do not need to understand or know about RLAs already.
...

We believe that the insights gleaned from this experiment will both contribute to generalized knowledge about how to increase confidence in elections, and RLAs in Colorado, and provide a path for other states besides Colorado to implement, and market, RLAs to their constituents.

---

## Research Questions

* What are effective strategies to educate voters about how RLAs work?

* Specifically, what characteristics of RLAs are most effective in increasing voters’ confidence in the integrity of the election results? 

* Do different strategies work better for different subgroups?

---

## Experimental Setup

_Describe how the research question can be answered with an experiment, comment on the methodology used. For example, argue why a randomized experiment is useful to answer the research question._

_This section should be a "how-to" guide for executing your experiment. In theory, someone should be able to execute your experiment after reading this section._

The research question can be answered using an experiment to test the efficacy of different messages on increasing confidence in election systems by providing information about RLAs.

The methodology for this experiment...
we will use three different messages (?) with a pre- and post-test question to gauge the effect of the message.

*UPDATE*

### Sample recruitment

_How, where and when will your participants be recruited? Who are your participants? Why is this an appropriate sample for studying the research problems above? How are the data going to be collected?_

Participants will be recruited through Lucid, which allows us to target a representative sample of US adults. Apart from Colorado, several other states have recently or are planning to use RLAs in the future and the goal of using a nationally representative sample is to gain generalizable insights about the potential benefits of well-communicated information about RLAs on voter confidence in the election.

*Power calculation*

Example:

We will recruit respondents in Kenya and Nigeria using Facebook advertisements targeted
to users 18 years and older living in these countries. To achieve balance on gender within
our sample, we create separate ads targeting men and women in both countries. Our target sample size is 1,500 respondents in each country for our pilot. We anticipate that our sample will look similar to the overall Facebook population in these countries, which tends to be more male, more urban, and more educated than the overall population (Rosenzweig et al., 2020). We will analyze how our sample compares to both the Facebook population and the general population in Kenya and Nigeria using Facebook’s advertising API data and nationally representative Afrobarometer surveys conducted in both countries.

When users click on the “Send Message” button on our advertisement, a Messenger conversation will open with our Facebook page, starting a conversation with a chatbot programmed to implement the survey. In contrast to sending users to an external survey platform such as Qualtrics, the benefit of the chatbot is that we keep users on the Facebook platform, with which they are likely more familiar, and maintain a realistic setting in which users might encounter online misinformation.


### Treatment

_Please explain your experimental interventions in detail here. Please include a flow chart/diagram that helps explain to readers your experimental setup and procedure._

_You should provide details for each treatment arm here. Remember, visuals help! You can provide images or screenshots of what the actual experiment will look like to participants._

_You should also provide the rationale for choosing the treatment arms._


**Source: You can draw inspirations from your team discussions, discussion with the partner, as well as previous treatment interventions used in the literature.**

Example:

Drawing on the literature on experimental interventions to combat misinformation, we
include several treatments designed to reduce the spread of misinformation online, which
are targeted both at the respondent level and the headline level. This list of treatments
also draws on real-world interventions that companies and platforms have instituted to
combat misinformation. The treatments are presented in Table 1.

Respondent-level treatments and headline-level treatments are implemented as separate
factors, each of which has an empty baseline level that is the control. So respondents may be
assigned the pure control condition, one of the respondent-level treatments but no headline level treatment, one of the headline-level treatments but no respondent-level treatment, or
one of the respondent-level treatments and one of the headline-level treatments.

** add 3 treatments and control group
control respondent - treated with paragraph of similar length to treament effects on importance of elections

<center>
**Table 1**
</center>

| Shorthand Name | Treatment Level | Treatment 
|:----:|:----:|:----:|
| 1. Facebook tips | Respondent |Facebook’s “Tips to Spot False News”|
| 2. AfricaCheck tips | Respondent | Africacheck.org’s guide:
“How to vet information during a pandemic”|
| 3. Video training | Respondent | Videos (links) | 
| 4. Emotion suppression | Respondent | Prompt: “As you view and read the headlines, if you have any feelings, please try your best not to let those feelings show. Read all of the headlines carefully, but try to behave so that someone watching you would not know that you are feeling anything at all” (Gross, 1998). | 
| 5. Pledge | Respondent | Prompt: Respondents will be asked if they want to keep their family and friends safe from COVID-19, if they knew COVID-19 misinformation can be dangerous, and if they’re willing to take either a private or public pledge to help identify and call out COVID-19 misinformation online (see B.4.4). | 
| 6. Accuracy nudge |  Respondent |  Placebo headline: “To the best of your knowledge, is this headline accurate?” (Pennycook et al., 2020, 2019). | 
| 7. Deliberation nudge|  Respondent | Placebo headline: “In a few words, please say why you would ike to share or why you would not like to share this headline.” [open text response] | 
| 8. Related articles | Headline | Facebook-style related stories: below story,
show one other story which corrects a false news story | 
| 9. Factcheck  | Headline  | Fact checking flag from third party PesaCheck or AfricaCheck | 
| 10. More information |  Headline  | Provides a link to “Get the facts about COVID-19” | 
| 11. Real information  | Headline |  Provides a true statement: “According to the WHO,
there is currently no proven cure for COVID-19. | 
| 12. Control  | N/A  | Control condition | 

<center>Table 1. Description of interventions included in the experiment</center>

Treatments 1, 2, 3, 8, 9 and 10 are derived from interventions currently being used by
social media platforms including Facebook, Twitter, and WhatsApp. For instance, Guess
et al. (2020) find that reading Facebook’s tips for spotting untrustworthy news improved
participants’ ability to discern false from true headlines in the US and India.





### Outcomes

_How will you measure and analyze both primary and secondary outcomes of interest? How do they help you address the research questions?_

**Source: You can discuss with the partners to understand whether the outcomes are meaningful for them. **

Primary:
(1) Is communicating about RLAs an effective way to increase trust in election system for the US adult population?

Secondary;
(2) Which messages about RLAs are the most salient? 

Example:

We are primarily interested in decreasing sharing of harmful false information about
COVID-19 cures and treatments. However, we would simultaneously wish to constrain
negative impacts on sharing of useful information about transmission and best practices
from verified sources. Specifically, we are interested in three outcomes: 

Primary:

(1) Increasing voters confidence for US adults that ballots are correctly counted in the state and national elections.

Secondary:

(2) Most effective messages to build trust - logical, emotional.

(3) Are certain messages more effective for certain subgroups?


#### Primary Outcomes

_ Describe the primary outcome. Argue why this is a relevant metric for answering the research questions. If the design of your experiment is more involved or has multiple outcomes of interest, feel free to add additional sections as necessary._

Example: 

_You should lay out the questions you use to measure your outcomes._

*UPDATE - NATE TO SEND*

We measure trust in elections from RLAs through two questions:

measure efefctiveness of treament comapred to control 

* Would you like to share this post on your timeline?
* Would you like to send this post to a friend on Messenger?

We use a pre-test / post-test design. Prior to treatment, we show respondents four media posts from their country (two true and two false in random order) randomly sourced from our stimuli set. For each stimulus, we ask the above self-reported sharing intention questions. Respondents are then asked a series of questions about their media consumption, and are then randomly assigned treatment according to the experimental design. If assigned to one of the respondent level treatments, they are administered the relevant treatment. 

They are then shown four additional stimuli (two true and two false), selected from the remaining stimuli that they were not shown pre-treatment. If the respondent is assigned a headline-level treatment, this treatment is applied only to the misinformation stimuli, as flags and fact-checking labels are not generally applied to true information from verified sources. For each of the stimuli
we again ask the same self-reported sharing intention questions.

Because of random assignment, we expect to see no systematic differences in pre-test interest in sharing either true or untrue stimuli across treatment conditions, conditional on covariates.

#### Secondary Outcomes

_Secondary outcomes are things that you also wish to investigate in addition to the primary outcomes. Sometimes these outcomes can shed light on the mechanisms through which interventions work. Sometimes they help ensure that your intervention does not lead to unintended effects._

compare all treatments to each other 

see which message is more effective 
run multiple hypothesis test between each treatment group

Example: 

Additionally, we measure secondary behavioral outcomes which allows us to further
investigate the extent to which treatments may suppress the sharing of true information.



### Covariates

_Which covariates will you include in the experiment and why? This selection can for example depend on expected treatment heterogeneity. Some common covariates include age, partisanship, Internet usage, location, etc. Explain why the covariates are important in your context._

**Source: You can check what are the most commonly used covariates in other experiments in the literature. Moreover, it would be helpful to think about what the main covariates are to collect in your experimental context.**

control for people with strong/unwavering views to actually measure effect

Example:

The existing misinformation literature centered around studies conducted with respondents in North America and Europe, most often focuses on political ideology (Pennycook et al., 2019), cognition or inclination to deliberate (Bago et al., 2020), and media literacy (Guess et al., 2020). Our study expands this focus to explore heterogeneity with respect to additional respondent covariates. Outside of contexts where partisanship is a salient identity and lens through which individuals interpret news and information, what are the likely sources of heterogeneity in individuals’ receptivity to interventions to combat the spread of misinformation?

In addition to the demographic covariates such as age, gender, education, we also
include specific questions regarding knowledge of and concern about COVID-19, an index
of scientific views, beliefs about government efficacy in the current coronavirus pandemic,
religious behaviors and beliefs, locus of control, and digital literacy. These variables capture what might be sources of heterogeneity in responses
to misinformation: age, analytical thinking (captured in our scientific beliefs index), and
need for closure (captured in our concern regarding COVID-19 concern measurement and
the beliefs about government efficacy measurement) (Wittenberg and Berinsky, 2020).


---

## Hypotheses

_Discuss how you would map the research questions into testable hypotheses. For example, if your goal is to find some prototypes for further exploration, which kind of test would you want to conduct? If your goal is to figure out if an intervention works better for one specific group, how would you formulate the hypothesis?_

_Be clear about the measurement and the direction of hypothesized change._

_How do you plan to address the problem of multiple hypotheses testing? If you are making a final recommendation rather than selecting some for future exploration, you might want to choose the more conservative correction methods._

**Source: The hypotheses should address your research/business goals.**

Example:

**Primary:**

The primary hypotheses that we want to measure would be whether any of the treatments to communicate about RLAs is effective in increasing voter trust in election systems.


**Secondary (Hypotheses to inform industry practice)**

We care about the outcome (reducing the spread
of COVID-19 misinformation) and understanding which types of people are nudged toward
this outcome by particular treatments. Therefore, we plan to examine how a few select
treatments interact with particular covariates of interest. 

We select the below treatments because these are currently, or were previously, used by social media companies including Facebook and Twitter. The below covariates were selected as those that social media companies directly collect or have access to, and therefore could more easily use for targeting interventions. For our covariates of interest, we will divide these into two groups for any binary variables (i.e. indicator for male) and split on the median value for continuous variables to test two subgroups (i.e. age $\geq$ median and age $<$ median)

Treatments:

* Facebook tips (respondent)
* AfricaCheck tips (respondent)
* Factcheck (headline)
* More information (headline)
* Related articles (headline)

Covariates:

* Age
* Male
* Education

We hypothesize that the three headline-level treatments listed above will perform better
among more educated users, older people, and among women, compared to the less educated,
younger and male respondents. We expect that the two respondent-level treatments
will reduce sharing of misinformation more among less-educated respondents than those
with more education.

We hypothesize that learning about RLAs will have at least a small positive effect on trust in election systems. 

*UPDATE*

---

## Analysis

_Label and index your data: outcomes, treatments, covariates. Formally describe how you test the hypotheses described earlier._

**Source: Analysis should also follow your hypotheses. For each of your hypotheses, what analysis will allow you to test the hypotheses?**

Look at pre-treatment, post-treatment. Take movement on scale to find the average treatment effect, compared averages across treatments.

one-sided t-test 

analyze by sub-groups 
- we expect that...

*UPDATE*

Example:

For the primary and secondary outcomes discussed above, we report average outcomes under each headline factor level and separately each respondent factor level, marginalizing over a balanced distribution of levels of the other factor. In other words, we analyze the average marginal effects.

To test hypotheses regarding specific heterogeneous response,
we again average across the relevant outcomes, and compare estimates across the two groups defined by the covariates above.

Given that testing these treatment-covariate combinations will result in a large number of
unique tests, we will adjust for multiple hypothesis testing for response heterogeneity by
reporting tests under different correction methods.

_Reminder: the correction method also depends on your business objective._

---

## Power Calculations
_A crucial function of the PAP is to help you calculate the sample size you would need to detect a hypothesized treatment effect. Depending on your experimental design, please use the relevant tutorial for power calculation code._

_[Here](https://www.povertyactionlab.org/resource/conduct-power-calculations) is a resource containing principles for running power calculations._

_Please indicate your choice of the minimum detectable effect and rationale. There is no universal rule of thumb for determining a "good" minimum detectable effect. For researchers, this might be informed by the existing literature: what have previous studies of comparable interventions found? What would be the smallest effect size that would be interesting to be able to reject? For partners, this might be the smallest effect that would still make it worthwhile to run this program (from their own perspective, or from a funder’s or policymaker’s perspective), as opposed to dedicating resources elsewhere. This may mean the smallest effect that meets their cost-benefit assessment, the smallest effect that is clinically relevant, or some other benchmark._

_Please include the code, result, and figures from your power calculations._

**Source: If your experiment involves multiple treatment arms, and you are comparing each of them against the control, you can adapt the power calculation code in the Multiple hypothesis testing tutorial. If you are using a factorial design experiment, you need to adapt the code in Factorial Design Tutorial, following the hypotheses that you outlined in the above section and the correction method that suits your objective.**


### Load required packages

```{r load_packages}
# you can install the packages you need for power calculation and analysis
if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse)
pacman::p_load(randomizr)
pacman::p_load(estimatr)
pacman::p_load(kableExtra)
pacman::p_load(ggthemes)
pacman::p_load(reshape2)
pacman::p_load(bindata)
```

*UPDATE POWER CALCULATIONS*

```{r power}

# Add your code for power calculation here

# If you are using a factorial design,
# remember to use both the lm_interacted() function in 'lm_model' code chunk and the 'power_simulated' code chunk.

# Please adjust the number of hypotheses, hypotheses type, effect size, and treatment-control split etc. in your simulation.

power_calculator <- function(mu_1, # treatment mean 
                             mu_0, # control mean
                             sigma, # standard deviation
                             alpha=0.05, # significance level
                             N, # experiment size
                             hypothesis = 'two.tailed' # type of hypothesis
){ 
  # The tails of our statistic's distribution
  lowertail <- (abs(mu_1 - mu_0)*sqrt(N))/(2*sigma) # note that this is Z inside the power formula
  uppertail <- -1*lowertail # upper tail matters if we are interested in testing if u1 < u0
  if(hypothesis == 'two.tailed'){
    # HA: \mu_1 \neq \mu_0
    # qnorm(1-a) gives z_a; pnorm(x, lower.tail=TRUE) gives prob(X<=x); pnorm(z, lower.tail=FALSE) gives prob(X>x); 
    pwr <- pnorm(lowertail - qnorm(1-alpha/2), lower.tail=TRUE) + 1- pnorm(uppertail- qnorm(1-alpha/2), lower.tail=FALSE) 
  } else if(hypothesis == 'greater'){
    # HA: \mu_1 > \mu_0
    pwr <- pnorm(lowertail - qnorm(1-alpha), lower.tail=TRUE)
  } else if(hypothesis == 'lower'){
    # HA: \mu_1 < \mu_0
    pwr <- 1 - pnorm(uppertail- qnorm(1-alpha), lower.tail=FALSE)     
  }
  return(pwr) 
} 

mu_1 = 0 # treatment mean
mu_0 = 0 # control mean
sigma = 0 # standard deviation
hypothesis = 'greater'  # type of hypothesis

# apply power calculator by plugging in the above parameters
pwr <- power_calculator(mu_1 = mu_1, 
                        mu_0 = mu_0, 
                        sigma = sigma,
                        alpha=0.05, 
                        N = 100,
                        hypothesis = hypothesis)

```

---

## Analysis Scripts
_Importantly, please include analysis scripts that can be directly applied to your experimental data. The data engineers should work to extract and organize experimental data so that the data scripts can be applied. Remember to always comment the code and add explanation after the code output._

**Source: The experimental design tutorials contain code for analyzing a dataset, including coding up the outcome variables, treatment variables, covariates, checking balance in treatment assignment and analyzing using regression models. **

Add t-test and code from tutorials - Anderson 

```{r analysis}
tibble::glimpse(df) # overview of variables in the data


```


## References
